{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as pimg\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import f1_score,classification_report\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = ()\n",
    "def load_data():\n",
    "    datasets = ['src']\n",
    "    output = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "        \n",
    "        for folder in os.listdir(dataset):\n",
    "            label = folder\n",
    "            folder_path = os.path.join(dataset, folder)\n",
    "            for file in tqdm(os.listdir(folder_path)):\n",
    "                \n",
    "                img_path = os.path.join(folder_path, file)\n",
    "                img = cv2.imread(img_path)\n",
    "                # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                # img = cv2.resize(img, IMAGE_SIZE) \n",
    "                \n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')   \n",
    "        \n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                #   rotation_range=15,\n",
    "                                #   width_shift_range=0.1,\n",
    "                                #   height_shift_range=0.1,\n",
    "                                #   shear_range=0.5,\n",
    "                                #   zoom_range=[0.8, 2.0],\n",
    "                                #   horizontal_flip=True,\n",
    "                                #   vertical_flip=True,\n",
    "                                #   fill_mode='nearest'\n",
    "#                                   )\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = train_datagen.flow_from_directory('./dataset/training_set',\n",
    "#                                                     target_size=(500, 500),\n",
    "#                                                     batch_size=3,\n",
    "#                                                     class_mode='categorical'\n",
    "#                                                     )\n",
    "\n",
    "# test_generator = test_datagen.flow_from_directory('./dataset/test_set',\n",
    "#                                                   target_size=(500, 500),\n",
    "#                                                   batch_size=3,\n",
    "#                                                   class_mode='categorical'\n",
    "#                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (256,256)\n",
    "batch_size = 16\n",
    "padding = 'same'\n",
    "classes = ['climaxForest', 'herbaceous', 'shrub', 'wasteland']\n",
    "data_path = 'src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_path, # same directory as training data\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3),padding=padding, input_shape = (*input_size, 3))) \n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),padding=padding)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding=padding))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3),padding=padding)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(16, (3, 3),padding=padding, input_shape = (*img_size, 3))) \n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3),padding=padding)) \n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3),padding=padding)) \n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dense(len(classes), activation='softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89b2aa35640a00fdcc6ea1e9193483026b25998ee45573a902a6563769629588"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
